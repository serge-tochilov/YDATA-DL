{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "[DL HW6] RNN For Text Classification.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOfsgy9F5fxQcbKkIvl3POG"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhVIfllSbqzX"
   },
   "source": [
    "Y-DATA 2020/21<br/>\n",
    "Deep Learning HW6<br/>\n",
    "Serge Tochilov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEVjCbDOumzs"
   },
   "source": [
    "# RNN for text classification and text generation\n",
    "### Dr. Omri Allouche 2021. YData Deep Learning Course\n",
    "\n",
    "[Open in Google Colab](https://colab.research.google.com/github/omriallouche/ydata_deep_learning_2021/blob/master/assignments/rnn_text_classification_generation/DL_rnn_text_classification_generation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHuhtSFtum0Y"
   },
   "source": [
    "In the first part of this exercise, we’ll continue our attempts to classify text using different network architectures. This time, we’ll try a LSTM. We'll use the Metrolyrics dataset we used in the previous exercise.  \n",
    "\n",
    "You are encouraged to review the code in [this](https://github.com/prakashpandey9/Text-Classification-Pytorch) repo, that contains implementation of several deep learning architectures for text classification in PyTorch. If you face time limitations, you're welcome to adapt it to your needs instead of writing your own code from scratch.\n",
    "\n",
    "In the second part of this exercise, you'll unleash the hidden creativity of your computer, by letting it generate Country songs (yeehaw!). You'll train a character-level RNN-based language model, and use it to generate new songs.\n",
    "\n",
    "### Special Note\n",
    "Our Deep Learning course was packed with both theory and practice. In a short time, you've got to learn the basics of deep learning theory and get hands-on experience training and using pretrained DL networks, while learning PyTorch.  \n",
    "Past exercises required a lot of work, and hopefully gave you a sense of the challenges and difficulties one faces when using deep learning in the real world. While the investment you've made in the course so far is enormous, I strongly encourage you to take a stab at this exercise. \n",
    "\n",
    "DL networks for NLP are much shallower than those for image classification. It's possible to construct your own networks from scratch, and achieve nice results. While I hope the theoretical foundations of RNNs are clear after our class sessions, getting your hands dirty with their implementation in PyTorch allows you to set breakpoints, watch the dimensions of the different layers and components and get a much better understand of theory, in addition to code that might prove useful later for your own projects. \n",
    "\n",
    "I tried to provide references for all parts that walk you through a very similar task (actually, the same task on a different dataset). I expect this exercise to require much less of your time than previous exercises.\n",
    "\n",
    "The exercise is aimed to help you get better understanding of the concepts. I am not looking for the optimal model performance, and don't look for extensive optimization of hyperparameters. The task we face in this exercise, namely the classification of the song’s genre from its text alone, is quite challenging, and we probably shouldn’t expect great results from our classifier. Don’t let this discourage you - not every task reaches a f1-score of 90%+.\n",
    "\n",
    "In fact, I chose this dataset is because it highlights several issues we face in machine learning models in the real world. Examples include:\n",
    "- The classes are highly imbalanced - try to think how this affects the network learning\n",
    "- Given the small amount of data for some classes, you might actually prefer to remove them from the dataset. How would you decide that?\n",
    "- NLP tasks often involve preprocessing (lowercasing, tokenization, lemmatization, stopwords removal etc.). The decision on the actual preprocessing pipeline depends on the task, and is often influenced by our believes about the data and exploratory analysis of it. Thinking consciously about these questions helps you be a better data scientist\n",
    "- Some songs contain no lyrics (for example, they just contain the text \"instrumental\"). Others include non-English characters. You'll often need to preprocess your data and make decisions as to what your network should actually get as input (think - how should you treat newline characters?)\n",
    "- While model performance on this dataset are not amazing, we can try to answer interesting follow-up questions - which genres are more similar to each other and are often confused? Do genres become more similar through the years? ...\n",
    "\n",
    "More issues will probably pop up while you're working on this task. If you face technical difficulties or find a step in the process that takes too long, please let me know. It would also be great if you share with the class code you wrote that speeds up some work (for example, a data loader class, a parsed dataset etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fHjTjJXum0d"
   },
   "source": [
    "## RNN for Text Classification\n",
    "In this section you'll write a text classifier using LSTM, to determine the genre of a song based on its lyrics.  \n",
    "The code needed for this section should be very similar to code you've written for the previous exercise, and use the same dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fX_YjBVdQRlO"
   },
   "source": [
    "> For preprocessing we mostly reused the code from HW5 which\n",
    "- drops new lines and all punctuation\n",
    "- makes all letters lowercase\n",
    "- anglicizes all diacritics\n",
    "- drops non-English songs\n",
    "- adds lyrics-specific stop words\n",
    "\n",
    "> For LSTM classification we adapted a Pytorch tutorial from https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html. Using $128$ embedding and hidden dimension size, after $5$ training epochs the model achieved $0.57$ f1-score.\n",
    "\n",
    "> To determine the predicted song's genre we find the most frequent genre among the words in a song's text. As in HW5, *Hip-Hop* is mostly classified correctly, while *Pop* and *Rock* are often mixed together."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AejLr3Tusaab"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vfMYmcd4s1ag"
   },
   "source": [
    "from pathlib import Path\n",
    "import os.path\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def load_file(data_dir, url, fname, unzip=False):\n",
    "\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fpath = data_dir + os.sep + fname\n",
    "    if Path(fpath).is_file():\n",
    "        print('skipping', fpath)\n",
    "        return fpath\n",
    "\n",
    "    print('downloading', fpath)\n",
    "    rsp = requests.get(url)\n",
    "    rsp.raise_for_status()\n",
    "    \n",
    "    with open(fpath, 'wb') as f:\n",
    "        f.write(rsp.content)\n",
    "\n",
    "    if unzip:\n",
    "        with ZipFile(fpath, 'r') as zip_obj:\n",
    "            zip_obj.extractall(path=data_dir)\n",
    "        \n",
    "    return fpath"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEOhHeQVs4PB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301497514,
     "user_tz": -180,
     "elapsed": 1720,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "040c5aac-eba6-43ad-817f-b4f089ebab9c"
   },
   "source": [
    "# https://github.com/omriallouche/ydata_deep_learning_2021/raw/a50abc90b6bc63a302870f42d5ebd2ab0bb43499/data/metrolyrics.parquet\n",
    "url = 'https://www.googleapis.com/drive/v3/files/1-T5W6sgkOVLNj59ep7rRqxJqTrpPIJxv?alt=media&key=AIzaSyA3oLxSbMs3Xd5uveO53eAWXXDTqxgJiF0'\n",
    "fpath = load_file('.', url, 'metrolyrics.parquet')\n",
    "\n",
    "df_songs = pd.read_parquet(fpath)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "skipping ./metrolyrics.parquet\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jBD8zGvs8ml",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301497519,
     "user_tz": -180,
     "elapsed": 1698,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "90546166-6512-4d7c-8def-4c93795b4a01"
   },
   "source": [
    "df_songs.info()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49976 entries, 204182 to 11180\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   song       49976 non-null  object\n",
      " 1   year       49976 non-null  int64 \n",
      " 2   artist     49976 non-null  object\n",
      " 3   genre      49976 non-null  object\n",
      " 4   lyrics     49976 non-null  object\n",
      " 5   num_chars  49976 non-null  int64 \n",
      " 6   sent       49976 non-null  object\n",
      " 7   num_words  49976 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 3.4+ MB\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "Faj4zU7MtELv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301499979,
     "user_tz": -180,
     "elapsed": 4119,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "3b7b4353-12b0-4356-e6c5-b8025f9e84d4"
   },
   "source": [
    "!pip install fasttext\n",
    "\n",
    "# 'https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz'\n",
    "url = 'https://drive.google.com/uc?export=download&id=1wtvl_kHElKySqK__C0y2xlJq0gavOM3m'\n",
    "load_file('.', url, 'lid.176.ftz')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (56.0.0)\n",
      "skipping ./lid.176.ftz\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./lid.176.ftz'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2gEsJhatkuf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301510344,
     "user_tz": -180,
     "elapsed": 14444,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "9d1202f3-d6aa-4a9d-abd6-ce481d26b0e8"
   },
   "source": [
    "import fasttext\n",
    "\n",
    "lang_model = fasttext.load_model('lid.176.ftz')\n",
    "\n",
    "df_songs['lang'] = df_songs['lyrics'].apply(\n",
    "    lambda t: lang_model.predict(' '.join(t.split('\\n')), k=1)[0][0].split('_')[-1][:2])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ks-Xn3EPff4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301510371,
     "user_tz": -180,
     "elapsed": 14433,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "dc1b266b-cd84-4c88-df49-ac988437f648"
   },
   "source": [
    "df_songs['lang'].value_counts()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "en    46434\n",
       "es     1409\n",
       "de      698\n",
       "fr      320\n",
       "it      287\n",
       "pt      119\n",
       "fi       86\n",
       "sv       65\n",
       "tr       60\n",
       "id       58\n",
       "no       50\n",
       "nl       45\n",
       "tl       40\n",
       "da       39\n",
       "sr       31\n",
       "ja       30\n",
       "pl       21\n",
       "lt       16\n",
       "sw       16\n",
       "lo       16\n",
       "hu       15\n",
       "hr       12\n",
       "eo       11\n",
       "la       10\n",
       "sl        8\n",
       "ht        6\n",
       "ro        6\n",
       "ca        5\n",
       "ru        5\n",
       "eu        5\n",
       "pm        5\n",
       "zh        4\n",
       "bs        4\n",
       "nn        4\n",
       "af        4\n",
       "fa        3\n",
       "sh        3\n",
       "jb        3\n",
       "az        2\n",
       "cy        2\n",
       "br        2\n",
       "qu        2\n",
       "lm        1\n",
       "sq        1\n",
       "gl        1\n",
       "sk        1\n",
       "ku        1\n",
       "cs        1\n",
       "ar        1\n",
       "ms        1\n",
       "io        1\n",
       "oc        1\n",
       "as        1\n",
       "nd        1\n",
       "ie        1\n",
       "gd        1\n",
       "et        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeundSqBswxg"
   },
   "source": [
    "> Most songs are in English, and we filter out other languages as most NLP tools are English-oriented."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hO2e3116PrmT"
   },
   "source": [
    "df_songs = df_songs[df_songs['lang'] == 'en']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JihYDAiotPUw"
   },
   "source": [
    "> Next we load stopwords from `nltk` add several lyric-specific stopwords such as **chorus**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzEVQQFnIL00",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301510812,
     "user_tz": -180,
     "elapsed": 14826,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "e401b010-ca2c-456f-8c39-962ca8653c70"
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download and import the stop word list\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lyric_stops = ['chorus', 'prechorus', '2x', '3x', '4x', 'repeat', 'verse']\n",
    "\n",
    "stop_words = stopwords.words('english') + lyric_stops"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zavUn38su6Q4"
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words=stop_words,\n",
    "    min_df=1e-4)\n",
    "X = vectorizer.fit_transform(df_songs['lyrics'])\n",
    "\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "training_data = df_songs['lyrics'].apply(analyzer).to_list()\n",
    "genres_data = df_songs['genre'].to_list()\n",
    "tt_split = int(len(training_data) * 0.8)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrq9Q7wryDrw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301522495,
     "user_tz": -180,
     "elapsed": 26462,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "bad8f21f-ebd1-4ff9-a886-bd398a6c4496"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "torch.manual_seed(1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f795558caf0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uV4ot3GfxPQG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301523556,
     "user_tz": -180,
     "elapsed": 27480,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "2c85b23c-93c4-4de6-b337-52ac2b16ce39"
   },
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "tag_to_ix = {'Pop': 0, 'Metal': 1, 'Hip-Hop': 2, 'Rock': 3, 'Country': 4}\n",
    "\n",
    "word_to_ix = {}\n",
    "\n",
    "# for each words-list (song)\n",
    "for song in training_data:\n",
    "    for word in song:\n",
    "\n",
    "        if word not in word_to_ix.keys():\n",
    "            # word has not been assigned an index yet\n",
    "\n",
    "            # assign each word with a unique index\n",
    "            word_to_ix[word] = len(word_to_ix)  \n",
    "\n",
    "print(len(word_to_ix), 'unique words')\n",
    "\n",
    "# these will usually be more like 32 or 64 dimensional.\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "103861 unique words\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DgIuc6i72qGk"
   },
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # the LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality `hidden_dim`\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # the linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        \n",
    "        return tag_scores"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i58IYOCESnSi"
   },
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpjaatIGSqnt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619308303544,
     "user_tz": -180,
     "elapsed": 679,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "1fc7664a-3e20-46ed-9235-d70c3f363f33"
   },
   "source": [
    "print(model)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (word_embeddings): Embedding(103861, 128)\n",
      "  (lstm): LSTM(128, 128)\n",
      "  (hidden2tag): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3ZbStxtHXw3H"
   },
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21HgU36A3YAH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619309354405,
     "user_tz": -180,
     "elapsed": 1033234,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "f552fdd3-56ea-4dfb-9bb3-d7d530a8a37e"
   },
   "source": [
    "# move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch: {epoch+1} of {EPOCHS}')\n",
    "\n",
    "    for i, (lyric, genre) in enumerate(zip(training_data[:tt_split], genres_data[:tt_split])):\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Song', i+1)\n",
    "\n",
    "        if len(lyric) == 0:\n",
    "            continue\n",
    "\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(lyric, word_to_ix).to(device)\n",
    "        targets = torch.tensor(\n",
    "            list(it.repeat(tag_to_ix[genre], len(sentence_in))),\n",
    "            dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model = model.to('cpu')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch: 1 of 5\n",
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n",
      "Song 10000\n",
      "Song 11000\n",
      "Song 12000\n",
      "Song 13000\n",
      "Song 14000\n",
      "Song 15000\n",
      "Song 16000\n",
      "Song 17000\n",
      "Song 18000\n",
      "Song 19000\n",
      "Song 20000\n",
      "Song 21000\n",
      "Song 22000\n",
      "Song 23000\n",
      "Song 24000\n",
      "Song 25000\n",
      "Song 26000\n",
      "Song 27000\n",
      "Song 28000\n",
      "Song 29000\n",
      "Song 30000\n",
      "Song 31000\n",
      "Song 32000\n",
      "Song 33000\n",
      "Song 34000\n",
      "Song 35000\n",
      "Song 36000\n",
      "Song 37000\n",
      "Epoch: 2 of 5\n",
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n",
      "Song 10000\n",
      "Song 11000\n",
      "Song 12000\n",
      "Song 13000\n",
      "Song 14000\n",
      "Song 15000\n",
      "Song 16000\n",
      "Song 17000\n",
      "Song 18000\n",
      "Song 19000\n",
      "Song 20000\n",
      "Song 21000\n",
      "Song 22000\n",
      "Song 23000\n",
      "Song 24000\n",
      "Song 25000\n",
      "Song 26000\n",
      "Song 27000\n",
      "Song 28000\n",
      "Song 29000\n",
      "Song 30000\n",
      "Song 31000\n",
      "Song 32000\n",
      "Song 33000\n",
      "Song 34000\n",
      "Song 35000\n",
      "Song 36000\n",
      "Song 37000\n",
      "Epoch: 3 of 5\n",
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n",
      "Song 10000\n",
      "Song 11000\n",
      "Song 12000\n",
      "Song 13000\n",
      "Song 14000\n",
      "Song 15000\n",
      "Song 16000\n",
      "Song 17000\n",
      "Song 18000\n",
      "Song 19000\n",
      "Song 20000\n",
      "Song 21000\n",
      "Song 22000\n",
      "Song 23000\n",
      "Song 24000\n",
      "Song 25000\n",
      "Song 26000\n",
      "Song 27000\n",
      "Song 28000\n",
      "Song 29000\n",
      "Song 30000\n",
      "Song 31000\n",
      "Song 32000\n",
      "Song 33000\n",
      "Song 34000\n",
      "Song 35000\n",
      "Song 36000\n",
      "Song 37000\n",
      "Epoch: 4 of 5\n",
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n",
      "Song 10000\n",
      "Song 11000\n",
      "Song 12000\n",
      "Song 13000\n",
      "Song 14000\n",
      "Song 15000\n",
      "Song 16000\n",
      "Song 17000\n",
      "Song 18000\n",
      "Song 19000\n",
      "Song 20000\n",
      "Song 21000\n",
      "Song 22000\n",
      "Song 23000\n",
      "Song 24000\n",
      "Song 25000\n",
      "Song 26000\n",
      "Song 27000\n",
      "Song 28000\n",
      "Song 29000\n",
      "Song 30000\n",
      "Song 31000\n",
      "Song 32000\n",
      "Song 33000\n",
      "Song 34000\n",
      "Song 35000\n",
      "Song 36000\n",
      "Song 37000\n",
      "Epoch: 5 of 5\n",
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n",
      "Song 10000\n",
      "Song 11000\n",
      "Song 12000\n",
      "Song 13000\n",
      "Song 14000\n",
      "Song 15000\n",
      "Song 16000\n",
      "Song 17000\n",
      "Song 18000\n",
      "Song 19000\n",
      "Song 20000\n",
      "Song 21000\n",
      "Song 22000\n",
      "Song 23000\n",
      "Song 24000\n",
      "Song 25000\n",
      "Song 26000\n",
      "Song 27000\n",
      "Song 28000\n",
      "Song 29000\n",
      "Song 30000\n",
      "Song 31000\n",
      "Song 32000\n",
      "Song 33000\n",
      "Song 34000\n",
      "Song 35000\n",
      "Song 36000\n",
      "Song 37000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jW7TOwxCTrl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619310232742,
     "user_tz": -180,
     "elapsed": 17929,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "9f9a2e47-3277-4732-d174-906b0be268af"
   },
   "source": [
    "model = model.to(device)\n",
    "\n",
    "genres_pred, genres_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (lyric, genre) in enumerate(zip(training_data[tt_split:], genres_data[tt_split:])):\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Song', i+1)\n",
    "\n",
    "        if len(lyric) == 0:\n",
    "            continue\n",
    "    \n",
    "        inputs = prepare_sequence(lyric, word_to_ix).to(device)\n",
    "        tag_scores = model(inputs).to('cpu')\n",
    "        _, pred = torch.max(tag_scores, 1)\n",
    "        _, pred = torch.max(torch.bincount(pred), 0)\n",
    "        genres_pred.append(pred)\n",
    "        genres_true.append(tag_to_ix[genre])\n",
    "\n",
    "model = model.to('cpu')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Song 1000\n",
      "Song 2000\n",
      "Song 3000\n",
      "Song 4000\n",
      "Song 5000\n",
      "Song 6000\n",
      "Song 7000\n",
      "Song 8000\n",
      "Song 9000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814
    },
    "id": "pziSlgtiJmjT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619310257053,
     "user_tz": -180,
     "elapsed": 1345,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "5e677d5b-0d2b-4638-f088-bc4b8ca3544d"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "def plot_cm(y, pred, target_names=''):\n",
    "\n",
    "    conf_m = confusion_matrix(y, pred)\n",
    "    print('Confusion matrix:\\n', conf_m, '\\n')\n",
    "\n",
    "    fractions = (conf_m / conf_m.sum(axis=0) * 100.0).round(2)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(fractions)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # set up axes\n",
    "    labels = [''] + list(target_names)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    # force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(genres_true, genres_pred, target_names=tag_to_ix.keys()), '\\n')\n",
    "plot_cm(genres_true, genres_pred, target_names=tag_to_ix.keys())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pop       0.49      0.38      0.43      1945\n",
      "       Metal       0.71      0.66      0.68      1657\n",
      "     Hip-Hop       0.87      0.78      0.83      1820\n",
      "        Rock       0.44      0.62      0.52      2534\n",
      "     Country       0.59      0.49      0.54      1329\n",
      "\n",
      "    accuracy                           0.59      9285\n",
      "   macro avg       0.62      0.59      0.60      9285\n",
      "weighted avg       0.61      0.59      0.59      9285\n",
      " \n",
      "\n",
      "Confusion matrix:\n",
      " [[ 735   87   80  883  160]\n",
      " [  68 1087   59  422   21]\n",
      " [ 181   36 1423  157   23]\n",
      " [ 369  302   53 1562  248]\n",
      " [ 154   17   13  489  656]] \n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opy5qym3um0l"
   },
   "source": [
    "## RNN for Text Generation\n",
    "In this section, we'll use an LSTM to generate new songs. You can pick any genre you like, or just use all genres. You can even try to generate songs in the style of a certain artist - remember that the Metrolyrics dataset contains the author of each song. \n",
    "\n",
    "For this, we’ll first train a character-based language model. We’ve mostly discussed in class the usage of RNNs to predict the next word given past words, but as we’ve mentioned in class, RNNs can also be used to learn sequences of characters.\n",
    "\n",
    "First, please go through the [PyTorch tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html) on generating family names. You can download a .py file or a jupyter notebook with the entire code of the tutorial. \n",
    "\n",
    "As a reminder of topics we've discussed in class, see Andrej Karpathy's popular blog post [\"The Unreasonable Effectiveness of Recurrent Neural Networks\"](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). You are also encouraged to view [this](https://gist.github.com/karpathy/d4dee566867f8291f086) vanilla implementation of a character-level RNN, written in numpy with just 100 lines of code, including the forward and backward passes.  \n",
    "\n",
    "Other tutorials that might prove useful:\n",
    "1. http://warmspringwinds.github.io/pytorch/rnns/2018/01/27/learning-to-generate-lyrics-and-music-with-recurrent-neural-networks/\n",
    "1. https://github.com/mcleonard/pytorch-charRNN\n",
    "1. https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdYkxzxpU-wT"
   },
   "source": [
    "> For LSTM text generation we adapted the recommended Pytorch tutorial from https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html. We used $256$ hidden dimension size, and to avoid gradient explosion added gradient clipping at $100$. The lyrics' alphabet includes lowercase English letters, digits and space. We trained the model on $1000$ songs as the inference is rather slow.\n",
    "\n",
    "> We generated $1024$-letters long lyrics for all genres, starting from `a` and `z`, with mixed results. The model learned how to separate words properly. The words start predominantly with `s`, `l`, sometimes with `o`. The lexicon is dominated by `see`, `sine`, `line` and similar words. The difference between genres isn't readily discernible and the starting letter doesn't seem to influence the generated text.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7lhA776DohrU"
   },
   "source": [
    "import string\n",
    "\n",
    "all_letters = ' ' + string.digits + string.ascii_lowercase\n",
    "\n",
    "# plus EOS marker\n",
    "n_letters = len(all_letters) + 1\n",
    "\n",
    "all_categories = list(tag_to_ix.keys())\n",
    "n_categories = len(all_categories)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDksU_hRxk-s",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619301556072,
     "user_tz": -180,
     "elapsed": 793,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "cb50479d-880c-4eb3-d2c2-af765d4c6e6e"
   },
   "source": [
    "all_letters, all_categories"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(' 0123456789abcdefghijklmnopqrstuvwxyz',\n",
       " ['Pop', 'Metal', 'Hip-Hop', 'Rock', 'Country'])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "g8tIuufTum0n"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        assert not torch.any(torch.isnan(hidden))\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        assert not torch.any(torch.isnan(input_combined))\n",
    "        hidden = self.i2h(input_combined)\n",
    "        assert not torch.any(torch.isnan(hidden)), torch.max(torch.abs(input_combined), 1)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "        \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ydJP2LoJpRbc"
   },
   "source": [
    "# one-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0, li] = 1\n",
    "    return tensor\n",
    "\n",
    "# one-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li, 0, all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "\n",
    "    # EOS\n",
    "    letter_indexes.append(n_letters - 1)\n",
    "\n",
    "    if torch.any(torch.LongTensor(letter_indexes) == -1):\n",
    "        print(line)\n",
    "    \n",
    "    return torch.LongTensor(letter_indexes)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MHjOSndVpZ_d"
   },
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "clipping = 1e02\n",
    "\n",
    "\n",
    "def train(rnn, device, category_tensor, input_line_tensor, target_line_tensor):\n",
    "    \n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden().to(device)\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        assert not torch.any(torch.isnan(hidden))\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), clipping)\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I6HNTj_61YTV"
   },
   "source": [
    "rnn = RNN(n_letters, 256, n_letters)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fu9ZBZjDppcT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619307920040,
     "user_tz": -180,
     "elapsed": 359586,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "b6410966-c4a8-4bf6-c8f5-d2592de2f3f4"
   },
   "source": [
    "rnn = rnn.to(device)\n",
    "\n",
    "for i, (lyric, genre) in enumerate(zip(training_data, genres_data)):\n",
    "\n",
    "    if len(lyric) == 0:\n",
    "        continue\n",
    "\n",
    "    if i > 1000:\n",
    "        break\n",
    "\n",
    "    category = categoryTensor(genre).to(device)\n",
    "    line = ' '.join(lyric).replace('_', ' ')\n",
    "    input = inputTensor(line).to(device)\n",
    "    target = targetTensor(line).to(device)\n",
    "\n",
    "    _, loss = train(rnn, device, category, input, target)\n",
    "\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f'Song {i+1}, loss {loss:.4f}')\n",
    "\n",
    "rnn = rnn.to('cpu')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Song 20, loss 3.3396\n",
      "Song 40, loss 3.0874\n",
      "Song 60, loss 2.9666\n",
      "Song 80, loss 2.9492\n",
      "Song 100, loss 3.0106\n",
      "Song 120, loss 3.0175\n",
      "Song 140, loss 2.9527\n",
      "Song 160, loss 2.9647\n",
      "Song 180, loss 3.0552\n",
      "Song 200, loss 2.9830\n",
      "Song 220, loss 3.0294\n",
      "Song 240, loss 2.9876\n",
      "Song 260, loss 3.0226\n",
      "Song 280, loss 3.0171\n",
      "Song 300, loss 3.0931\n",
      "Song 320, loss 2.9087\n",
      "Song 340, loss 2.9278\n",
      "Song 360, loss 2.8726\n",
      "Song 380, loss 2.9171\n",
      "Song 400, loss 2.8886\n",
      "Song 420, loss 2.9057\n",
      "Song 440, loss 2.8728\n",
      "Song 460, loss 2.9259\n",
      "Song 480, loss 2.8706\n",
      "Song 500, loss 2.8826\n",
      "Song 520, loss 2.7530\n",
      "Song 540, loss 2.8705\n",
      "Song 560, loss 2.7626\n",
      "Song 580, loss 2.7549\n",
      "Song 600, loss 2.7410\n",
      "Song 620, loss 2.8208\n",
      "Song 640, loss 2.6618\n",
      "Song 660, loss 2.8246\n",
      "Song 680, loss 2.7625\n",
      "Song 700, loss 2.6438\n",
      "Song 720, loss 2.7557\n",
      "Song 740, loss 2.7515\n",
      "Song 760, loss 2.6953\n",
      "Song 780, loss 2.7256\n",
      "Song 800, loss 2.5918\n",
      "Song 820, loss 2.6520\n",
      "Song 840, loss 2.5749\n",
      "Song 860, loss 2.6739\n",
      "Song 880, loss 2.7478\n",
      "Song 900, loss 2.6641\n",
      "Song 920, loss 2.7057\n",
      "Song 940, loss 2.6712\n",
      "Song 960, loss 2.5467\n",
      "Song 980, loss 2.6405\n",
      "Song 1000, loss 2.8131\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21yAWJa6wzTo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619309422273,
     "user_tz": -180,
     "elapsed": 2561,
     "user": {
      "displayName": "Serge Tochilov",
      "photoUrl": "",
      "userId": "17173954333523599003"
     }
    },
    "outputId": "08f82f02-a339-4f14-8319-4d7c4f9a81bb"
   },
   "source": [
    "# sample from a category and starting letter\n",
    "def sample(category, max_length, start_letter='a'):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_text = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_text += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_text\n",
    "        \n",
    "\n",
    "max_length = 1024\n",
    "\n",
    "rnn = rnn.to('cpu')\n",
    "\n",
    "for cat in all_categories:\n",
    "    print(f'{cat}:')\n",
    "    print(sample(cat, max_length))\n",
    "print()\n",
    "for cat in all_categories:\n",
    "    print(f'{cat}:')\n",
    "    print(sample(cat, max_length, start_letter='z'))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Pop:\n",
      "a sane seae seae seae seae seae seae seae see see see see see line seaee seae seae see see see see see line seae seae sine siae seaee sane seas seae see see see seee seae see see see see seees sani se line seae see see see lin see see sane seae seae seae seae seae sere see see see see line gea see see see see seee seas see see seee see see see see see seee seae see sere see see see see see see see see sane seae seas see sane seae sine seae seae seae seaee see see see see see seee see seas san see see see seae see see see see see see see see seae seae see sees seae seaees sone see sane seas see see see seae seae seae  ooe sine see seae seae seae seae seae seae seae see hee seae seaee hire seae seae seae seae seae seae seae seae seae seae seae seae seae seae seas see see see see lines sone seaeee sane seae seaee liaee sane seae sinee sane see see seae seae  ooe siee sane seae seae sine seae sees see see seee seae see see seae seas leae seae seae seae sease sine seae seae seaee seae seae seae seae seas see line s\n",
      "Metal:\n",
      "an cone seaee sire see seee line leae seaeee lines lini sere liri sere sine seae seae line seas see sere sine seae seae seae seae see seee seae seae seae seae tini sere sine seaee sine seaee sine seae seae seas seee seaee sinie sere see see seree sine seaee sine seae seaee sine seas see see linses sare see sine seae seae sane seae sine seae seae seae seae seae sane sine sere see sere see see see see see see see sere seee seae seae seae seae line seae seae seae seae seae seae line line line seae seae sine seae sine sine seae sine line seae seae seae seae seae seae siee seae seae sine sare seae see see lire line seae seae seae line seae seae seae seae sini sans seae line seae seane lire lines sare seee seaee sine seae seae seae sine sine seae seae seae seae line seae seae liae seae seae seae seae seae seae seaee sine seae seae seaee sine seas see see line seae seaee sine seae seae seae seae seae seae seae seae seas see see see see sere line sine seae seae seae seae sane seae seae see sere seae seae sease sare se\n",
      "Hip-Hop:\n",
      "an sane san see line sine sin see sine sine sine siae sea see sea se sere seas seas sea se ser se sere seas sea se ser see sine sine sine sin seee sane sine siae  ooee sine siae sea line sine sine sine sin sea se seres saness sanes line sine sine sines lire se line sine sine sine sin see sine  aane sine sin see sea se see se sine seas seas lirs sea se sine sine sine sine sin see sin sea se sere sine tane sine sine sine seas seas le se see sea se see sin sane sine sine sine sine sine sin see sire sine sine sines sane sine sinees sane le sire  ooe see sane sine siae seas see line sine sine sine sine sine sine sine sine sine sines sane sine sinee sane sine sine liae sea sine sine sine sine seas sea see sea se see  aae se siness sane se sine sian sea sire line sine siae sea seees line sine sine sea sire sine sine sine line lin see sea sine sine sine seas seas sea line sine sine sine sine sease sine sine sane seas sea se ser see sire lone sine sine seas sea se see se sea se sine sine sine sine line sin see sine sin\n",
      "Rock:\n",
      "an sone sine sine seae seae line seae seae seae seae seae seas sine seae seae seae seae seae seas lore seae sine seae seae ling seae  ooee seae seae seae seae siee line seas see see see siee seae seae seae seae seae seae seae seaee sane seae  ooees sans see see line siae  oon see seees sane seas see see see line seae see see see see seas seee see see line seae seae line seae seae line seae seaee sini see see see hine seae seae seae seae seae line seae seae seae seae seae sines sone line sine seae seas see see see seae seae sine seae see line sine seaee sine seae line sine seae seae line sine seae seae seae sine seaee sinin  aoee seaee sani see see see see see sine seas seee sine seae seae seae seas ling seae seae see see see line seae seae seae seae seae seaee sine seae seae seae seae seae sine ser see see seee sine seaee gine seae see seae see hire seas seee sine sane line seae seae seae sine sere sines sane seaee sine seae seaee sane seae  ooee seee seaee sine seae seae seae seae seae seae seae seae seae sea\n",
      "Country:\n",
      "an sone seae  aoe se sere see see line sines sane seae seae seae seae seae seae sane seae sire seas see hine sire sere see see see seee seae seae seas see see see seae seae line sease sinee sane seaees sane seae  ooe se sere seae  ooe se sere see siee sine seae seae seae  aoe se sine seae seaee sane seae seaee liness seae see seee seae see seae seae seae seae seae seae seaee sinees sane sere see see sine sine seas see see see see sine seae seae sone seases line seaee sine seae seae seae seee seae see line seas see see line line seae seae siness seane sane seae seae seee seas sene seae seae seas see sere see seee seaees sanee sini se see see see see see line sone sine seas sine seae line tine seae seae seae seae seas see lone sere see see see see see see see sere see see line seae seae seae seas see see see see see see seeee sines sane seae seae seae  ooe se sere see see seee seae sease sine seae seae seae  ooe se sere see see hin see sines sane seae seaee sine seae sine seae  aoe se sere see see see see see se\n",
      "\n",
      "Pop:\n",
      "z sone seaee seae leae seae seae seae seae  oae sine seae see see seae seae seae seae seaee ser see see eane seae seae  ooe se see see see see see see see lin see see sare seae  ioe se line seae seas seas seae seae seae seae seaee hiae seae seae sie see see seee seas see see see see see see see see see see see see see see seae  ooe se line seaee seae see see see see seae  ooe see see seee seae seae seae see see see see see seae seae seae seae sine seae seae see sane seae seae seae  oae se see see sare seaee sane line seae seae line seaes sanee sane seae seae  ooe  ooe  ooe se see see see see see see seae seaee seas see see see seaee sane leae seae seae see sane seae see see see seee see see sine see see see see seae seae seae seae seae seae see see see seae seae seae see see see see see see see see line seas see see see see sane sanee sans see see see see see see see seee seae see lines line seae  ooe see see san see see see sane seae  ooe se seee seae seae seae seae seae seae  ooe  oane seas see see san seee \n",
      "Metal:\n",
      "z sone line sean sine seae sine seae seae line seae seae seae seae seae seae tire sere seee line seae seae seae seae seae seas see see sine seae seae seae seae seae seae seaee sane seaee lins see line seas see see sine sine seae seae see sane seae seae see see line seae liree seae tine sine seas seee line sine seae siee sere see see see ser see see see sine seae seae seae seaee sine seae seae siee line sere see see line sere see see sine sere see see see see sere see see see see see see see see see see sere see see sere see see see seee seae seae sire seae see seee seee seee seeer sare see see see see see seee seae seae seae see see sere see see see see lere lere see see see see see see see sine sins see lone seae seae seas ree see see sane seae seaee siness seas see see see see sere see eane lone seaee sine sine sere see see line leae seae seae see seee seae seae seae seae sine seae seae sine seae seas line seae sere see see see see see lere see sere see see ser sere lere seree seae see see see see sine seae \n",
      "Hip-Hop:\n",
      "z sone sine sine sines sane sea sine sine sine seas lire sine sine sine line sine sine sine sine sine line sin sanes sine sine liness sane se sine sine sine sine sin see line sine sine seas seas seas see seas sease sini gines hone sine sine siae sea se see se sea se sine sine sine sine sine sine sine sine sine sine sine sine lin  aone siae see sane seas tine sine sine line line sine sine sine sine line seas sea see sea se le se sin sea se see se sea se sine  ooee sine sine sin see sines sane le sins sanes sane sine sere sea line siae sine sine sine sine seas sea se ser see sine siae sea se see sire sine sine sine sine sine sine seas sea se see sine sine line sin see sine sine sine seas sanee sanes sane siaee sane sine line line sine sin see sine siaees sane sine sine sine seas sea se ser seee sane sine sine siae se sine sine sine line sine line sin see sine sines sane sine sine sine sine seas seas line sine sin  ooe se sire sines sane sine sines sare se sine sine sine sine sines sane sinee sane sanese sarin se\n",
      "Rock:\n",
      "ze sone line seae seae sine seae sane seae seae seae seaee sine seae seae ser see see see see sine sere see see sees see see seaee sane see seaee sane seaes sane seae ling seaee sine seae seaee sine seae seae seaee siae seae seae line seas leae seae line seaee sine seae seas see see see see see see seee seas see seees sanee sane seae seae sine seae tine seae see sing seae seae seae seae line seae seae seae sines sane seae seae seae sine seae sere see see sine seae seae seae line seae seae seas see seae seae  ooe se see sine seae sines sane see line seae seae seae see see see see line sease seaee siae see see sine seae line seae seae seae sine seas see seae seae seae line seae seae seaee sine seae line seaee sine seae seae seae lines sane seae sane seae seae seae seae see seee seaee sine seae seae sine seae seae seae seae seane sine sere see see see see see see see see see see seee seae seae seae seae seae seas see see siee seae seae seae seae see see see see see seee seae seas seeee sane see lones sane line se\n",
      "Country:\n",
      "z son see see see see sin see see see seeess sane sere see see see see sine seae seae seae seae see see see sine seae seae seaee sine sine see lin  ooe se sere see see see sere seee seae seae seae seae seas seae  ooe se sere seae seae seae  aoe se sere seee seae seae seae seae seae seae sines lines sani se see sine sine ling seaee sine seae seae seas see see see sane seae seae  oon  oae se lire seae seae seae sine seae seaees sane seae seae seae sine lire sere see sine line seas line seae seae seae seae seaee sine seae seas see sine seae sines sare seee seaee sinese seree seae seaee sine seae seas lines sani sin seee seae line seae seae see see see see seee seae seas see line sine sine sere see see see see line sines sane seae see seee seae seae seee seaee sine seae  ooe se sere see sin see see seee seae seae seae seae seaee sire seae seae seae seaee lines sane seae seae see see seee seae seae seae see linee sane seae seae seae ser hines sonee sine seae seae  ooe se ser see see see see sane sing seae seae seae\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIyG2zWYum0n"
   },
   "source": [
    "### Final Tips\n",
    "As a final tip, I do encourage you to do most of the work first on your local machine. They say that Data Scientists spend 80% of their time cleaning the data and preparing it for training (and 20% complaining about cleaning the data and preparing it). Handling these parts on your local machine usually mean you will spend less time complaining. You can switch to the cloud once your code runs and your pipeline is in place, for the actual training using a GPU.  \n",
    "\n",
    "I also encourage you to use a small subset of the dataset first, so things run smoothly. The Metrolyrics dataset contains over 300k songs. You can start with a much smaller set (even 3,000 songs) and try to train a network based on it. Once everything runs properly, add more data.\n",
    "\n",
    "Good luck!  \n",
    "Omri"
   ]
  }
 ]
}